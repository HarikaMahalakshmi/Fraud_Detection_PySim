# -*- coding: utf-8 -*-
"""fraudDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n9pnmpFGnbxzK8LT-p3q_HvgSm8HixWe

# **Fraud Detection in Financial Transactions**

---

## Introduction
This notebook aims to develop a predictive model to identify fraudulent transactions for a financial company.  
We use the dataset with 6,362,620 rows and 10 columns.  
The goal is to detect fraud proactively and provide actionable recommendations.
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, make_scorer, f1_score
from xgboost import XGBClassifier, plot_importance
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
import joblib
from sklearn.metrics import make_scorer, recall_score

"""---

## Data Loading & Cleaning
- Load CSV dataset.
- Handle missing values-but this dataset doesn't contain any missing values
-Duplicates handling-no duplicates found
- Verify data types and ensure consistency.
"""

df=pd.read_csv("Fraud.csv")
df.head()

df.columns

df.info()

df.isnull().sum()

df.duplicated().sum()

df.describe()

"""Transactions are spread across millions of accounts.

Senders are mostly unique (like customers making transactions once).

Receivers repeat more often (like companies or fraudsters receiving money from many).

The most common transaction type is CASH_OUT.

"""

df.describe(include=['object'])

df["isFraud"].value_counts()

df["isFraud"].value_counts(normalize=True) * 100

"""## Exploratory Data Analysis (EDA)
-Outlier analysis and multicollinearity detection
-Analyze class distribution (fraud vs non-fraud).

-Visualize feature distributions using histograms and boxplots.

-Explore bivariate relationships between features and target.

-Correlation analysis and pairplots to identify patterns.

-Insights derived from EDA for fraud detection.
"""

import matplotlib.pyplot as plt
import seaborn as sns
ax = sns.countplot(x='isFraud', data=df)
ax.set_title('Class balance')
plt.show()

"""This count plot for isFraud shows a highly imbalanced dataset: the vast majority of transactions are non-fraudulent (0), while fraudulent transactions (1) are extremely rare.

Implications:
Training a model without addressing this imbalance can lead to poor detection of fraud. A naive model predicting all transactions as non-fraud would achieve high accuracy but fail on the minority class, making metrics like recall and F1-score crucial.
"""

#Checking if certain types of transactions are more prone to fraud.
fraud_rate_by_type = df.groupby('type')['isFraud'].mean().sort_values(ascending=False)
print(fraud_rate_by_type)
fraud_rate_by_type.plot(kind='bar')
plt.title('Fraud rate by transaction type')
plt.show()

"""TRANSFER and CASH_OUT are the primary sources of fraud."""

pivot_table_analysis = df.pivot_table(
    index='type',
    values='isFraud',
    aggfunc=['count', 'mean'],
    margins=True
)
pivot_table_analysis.columns = ['Count of Transactions', 'Fraud Rate']
pivot_table_analysis['Fraud Rate'] = pivot_table_analysis['Fraud Rate'] * 100
print(pivot_table_analysis)

pivot_table_analysis = df.pivot_table(
    index='type',
    values=['isFraud', 'amount', 'isFlaggedFraud'],
    aggfunc=['mean', 'std'],
    margins=True
)

# Create a color map for the gradient
cm = sns.light_palette("blue", as_cmap=True)

# Apply the gradient styling to the table
styled_table = pivot_table_analysis.style.background_gradient(cmap=cm)

# To display the styled table, you must run this line in a notebook environment
styled_table

sns.histplot(data=df, x='amount', bins=50)
plt.title('Distribution of Transaction Amounts')
plt.xlabel('Amount')
plt.ylabel('Frequency')
plt.show()

"""Large number of outliers identified"""

# box plot to compare the distribution of amounts
# for fraudulent (1) vs. non-fraudulent (0) transactions
sns.boxplot(x='isFraud', y='amount', data=df)

plt.title('Transaction Amount Distribution by Fraud Status')
plt.xlabel('Is Fraud')
plt.ylabel('Amount')
plt.yscale('log') # Use a log scale due to the high skew
plt.show()

contingency_table = pd.crosstab(df['isFlaggedFraud'], df['isFraud'])
styled_table = contingency_table.style.background_gradient(
    cmap=sns.light_palette("green", as_cmap=True)
).format('{:,}')

styled_table

"""The contingency table shows the relationship between isFraud and isFlaggedFraud. It indicates, for actual fraudulent transactions (isFraud = 1), how many were correctly flagged (isFlaggedFraud = 1).

Top-left (600,250): Transactions that are not fraud and were not flagged – correct negatives.

Top-right (361): Transactions that are fraudulent but not flagged – false negatives (missed frauds).
"""

numerical_cols = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']

# Create the correlation matrix
correlation_matrix = df[numerical_cols].corr()

# Create a heatmap to visualize the correlations
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""Features that are having multicollinearity are:


*   oldbalanceOrg vs newbalanceOrg
*   oldbalanceDest vs newbalanceDest



"""

# Take a random sample of the data (e.g., 50,000 rows)
sample_df = df.sample(n=50000, random_state=42)

# Select the numerical columns you want to visualize
numerical_cols = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']

# Create the pair plot using the sampled data
sns.pairplot(sample_df[numerical_cols])

# Display the plot
plt.show()

df.head()

"""## Feature Engineering & Selection

* Encode categorical features.

* Create additional features that might help model performance.

* Handle class imbalance using SMOTE

* Split dataset into training and testing sets.
"""

df_feat = df.copy()
df_feat.head()

# time features
df_feat['day']  = (df_feat['step'] // 24).astype(int)
df_feat['hour'] = (df_feat['step'] % 24).astype(int)

# transaction type flags
df_feat['is_cash_in']  = (df_feat['type'] == 'CASH_IN').astype(int)
df_feat['is_cash_out'] = (df_feat['type'] == 'CASH_OUT').astype(int)
df_feat['is_debit']    = (df_feat['type'] == 'DEBIT').astype(int)
df_feat['is_payment']  = (df_feat['type'] == 'PAYMENT').astype(int)
df_feat['is_transfer'] = (df_feat['type'] == 'TRANSFER').astype(int)

# merchant destination (dest starts with 'M')
df_feat['is_merchant_dest'] = df_feat['nameDest'].str.startswith('M').fillna(False).astype(int)

# error-based features: how much balances deviate
df_feat['orig_txn_diff'] = df_feat['newbalanceOrig'] + df_feat['amount'] - df_feat['oldbalanceOrg']
df_feat['dest_txn_diff'] = df_feat['oldbalanceDest'] + df_feat['amount'] - df_feat['newbalanceDest']

# binary indicators: whether there is any inconsistency
df_feat['orig_diff_flag'] = (df_feat['orig_txn_diff'] != 0).astype(int)
df_feat['dest_diff_flag'] = (df_feat['dest_txn_diff'] != 0).astype(int)

"""It creates meaningful ratios. By calculating amt_over_oldorg, it tells your model what percentage of a person's balance was used in a transaction, which is a much stronger signal for fraud than the raw amount or balance alone.

It cleans up the data. The log_amount transformation makes the data more normal, helping your model ignore extreme values and focus on the overall patterns. This is crucial for building a reliable model.
"""

eps = 1e-9
df_feat['amt_over_oldorg']  = df_feat['amount'] / (df_feat['oldbalanceOrg'] + eps)
df_feat['amt_over_olddest'] = df_feat['amount'] / (df_feat['oldbalanceDest'] + eps)
df_feat['log_amount'] = np.log1p(df_feat['amount'])

"""Removing Redundant features"""

# drop raw ID columns (not useful as features)
df_feat = df_feat.drop(columns=['nameOrig','nameDest','type','step'], errors='ignore')

# fill inf/nans (from division when denom 0)
df_feat.replace([np.inf, -np.inf], np.nan, inplace=True)
df_feat.fillna(0, inplace=True)

df_feat.head()

"""SMOTE Analysis and Splitting of Data For Training"""

from imblearn.over_sampling import SMOTE

# -----------------------
# 1. Separate features and target
# -----------------------
X = df_feat.drop(columns=['isFraud'])   # Features
y = df_feat['isFraud']                  # Target

# -----------------------
# 2. Split into train & test
# -----------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Before SMOTE:")
print(y_train.value_counts())

# -----------------------
# 3. Apply SMOTE on training set only
# -----------------------
smote = SMOTE(random_state=42, k_neighbors=5)  # k=5 default, can tune
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print("\nAfter SMOTE:")
print(y_train_smote.value_counts())

# -----------------------
# 4. Confirm shape
# -----------------------
print("\nShapes:")
print("X_train_smote:", X_train_smote.shape)
print("y_train_smote:", y_train_smote.shape)
print("X_test:", X_test.shape)
print("y_test:", y_test.shape)

"""## Model Building

* Select candidate models: Logistic Regression,, Random Forest, Decision Tree, XGBoost, AdaBoost, Naive Bayes

* Select the best-performing model based on Recall, F1-score, and ROC-AUC.
"""

# -----------------------------
# Define models
# -----------------------------
models = {
    "LogisticRegression": LogisticRegression(class_weight='balanced', max_iter=1000),
    "RandomForest": RandomForestClassifier(class_weight='balanced', n_estimators=200, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "DecisionTree": DecisionTreeClassifier(class_weight='balanced', random_state=42),
    "AdaBoost": AdaBoostClassifier(n_estimators=200, random_state=42),
    "NaiveBayes": GaussianNB()
}

# -----------------------------
# Determine minority class
# -----------------------------
fraud_class = y_test.value_counts().idxmin()  # dynamically picks minority class (1.0)

# -----------------------------
# Train, Predict, Evaluate
# -----------------------------
results = []

for name, model in models.items():
    print(f"\n========== Model: {name} ==========")
    model.fit(X_train_smote, y_train_smote)
    y_pred = model.predict(X_test)

    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test)[:,1]
    else:
        y_proba = model.decision_function(X_test)

    # Classification report
    report = classification_report(y_test, y_pred)
    print(report)

    # ROC-AUC
    roc = roc_auc_score(y_test, y_proba)
    print(f"ROC-AUC Score: {roc:.4f}")

    # Use output_dict with string keys
    report_dict = classification_report(y_test, y_pred, output_dict=True)
    # Convert keys to float safely
    report_dict_float = {float(k): v for k,v in report_dict.items() if k.replace('.','',1).isdigit()}

    results.append({
        "Model": name,
        "F1_Fraud": report_dict_float[fraud_class]['f1-score'],
        "Recall_Fraud": report_dict_float[fraud_class]['recall'],
        "Precision_Fraud": report_dict_float[fraud_class]['precision'],
        "ROC-AUC": roc
    })

# -----------------------------
# Create results dataframe
# -----------------------------
results_df = pd.DataFrame(results).sort_values(by='F1_Fraud', ascending=False)
print("\n===== Summary of all models =====")
print(results_df)

"""* Apply cross-validation on XGBoost(Here it was my selected model)

* Hyperparameter tuning using GridSearchCV
"""

# -----------------------------
# Cross-Validation (F1 for fraud class)
# -----------------------------
fraud_class = 1
f1_scorer = make_scorer(f1_score, pos_label=fraud_class)
skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

cv_scores = cross_val_score(xgb_model, X_train_smote, y_train_smote, cv=skf, scoring=f1_scorer)
print("Cross-validated F1-scores:", cv_scores)
print("Mean F1:", cv_scores.mean())

# -----------------------------
# Hyperparameter Tuning
# -----------------------------
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 6],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.7, 1],
    'colsample_bytree': [0.7, 1]
}
recall_scorer = make_scorer(recall_score, pos_label=1)
grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    scoring=recall_scorer,
    cv=3,
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train_smote, y_train_smote)
print("Best parameters:", grid_search.best_params_)
print("Best CV F1-score:", grid_search.best_score_)

# -----------------------------
# Train Final Model
# -----------------------------
final_model = grid_search.best_estimator_
final_model.fit(X_train_smote, y_train_smote)

# -----------------------------
# Evaluate on Test Set
# -----------------------------
y_pred = final_model.predict(X_test)
y_proba = final_model.predict_proba(X_test)[:,1]

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

roc = roc_auc_score(y_test, y_proba)
print("ROC-AUC Score:", roc)

"""## Model Evaluation

Evaluate the final model using:

* Confusion Matrix

* Classification Report (Precision, Recall, F1-score, Support).

* ROC Curve and Precision-Recall Curve.

* Identify and visualize top features contributing to fraud prediction.
"""

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred)


# Plot confusion matrix
plt.figure(figsize=(7,5))
sns.heatmap(
    cm_percent,
    annot=labels,
    fmt='',
    cmap='Blues',
    xticklabels=['Non-Fraud', 'Fraud'],
    yticklabels=['Non-Fraud', 'Fraud'],
    linewidths=1,
    linecolor='black',
    cbar=False
)
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix - Counts and Percentages', fontsize=14)
plt.show()

"""* Key Factors Predicting Fraud

List features most important for detecting fraud.
"""

# Get feature importances from the trained model
importances = final_model.feature_importances_

# Create a DataFrame for better visualization
feature_importances = pd.DataFrame({
    'feature': X_train.columns,
    'importance': importances
})

# Sort the features by importance
feature_importances = feature_importances.sort_values(by='importance', ascending=False)

# Plot the top 10 features
plt.figure(figsize=(10, 8))
sns.barplot(x='importance', y='feature', data=feature_importances.head(10))
plt.title('Top 10 Most Important Features for Fraud Prediction')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.show()

"""Large deviations from normal transactions: orig_diff_flag, orig_txn_diff, dest_diff_flag, dest_txn_diff

Unusually high amounts: amt_over_oldorg, amount

Unusual recipients or merchants: is_merchant_dest

Transaction type and balance changes: is_payment, is_debit, newbalanceOri

## Suggestions
Companies updating their systems should build fraud prevention directly into the design. This involves two main steps:

* Integrate real-time analysis: The new system needs to analyze every transaction instantly to catch fraud as it's happening.

* Set up smart rules: You should create a simple rule engine that works with your model to automatically flag or block suspicious transactions.

** To know if these changes are working, you should track key results: **

Check the money: The most important thing is to see a drop in financial losses from fraud.

Monitor your model: Look at its performance on new data. A good Recall score means it's catching fraud, and a good Precision score means it's not bothering customers with too many false alarms.

Listen to your customers: If user complaints about blocked transactions go down, it's a good sign the system is working well without disrupting the user experience.

Watch for new scams: A successful system must keep up with evolving fraud tactics.
"""

