step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).

type - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.

amount - amount of the transaction in local currency.

nameOrig - customer who started the transaction

oldbalanceOrg - initial balance before the transaction

newbalanceOrig - new balance after the transaction

nameDest - customer who is the recipient of the transaction

oldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).

newbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).

isFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent 
behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring 
to another account and then cashing out of the system.

isFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. 
An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.



Random Forest: It performed best because it's a team of many simple models. By combining their votes, it avoids mistakes and is great at finding complex patterns in your data.

XGBoost: It's a close second because it learns by correcting its own mistakes. It builds a series of models, with each one focused on fixing the errors of the previous one, making it very powerful.

Decision Tree: It did well but not as well as the others because it's a single model. It can overfit the data and is less stable than a team of models.

AdaBoost: It found most of the fraud but also had a lot of false alarms. It's too aggressive in finding the fraud and incorrectly flags many legitimate transactions.

Naive Bayes: It performed poorly because it made a bad assumption: it assumed that your features were independent of each other. Your heatmap showed this isn't true, which hurt its performance.

Logistic Regression: It performed the worst because it's a linear model. It can only find straight-line relationships, but your fraud data has complex, non-linear patterns that it can't understand.